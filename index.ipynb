{"cells": [{"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "ace4bcb150d5b97d72feacda06091be8", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["# Regularization\n", "\n", "Today you'll be creating several different linear regression models in a predictive machine learning context.\n", "\n", "In the cells below, we are importing relevant modules that you might need later on. We also load and prepare the dataset for you."]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "fc810633c7dca8c292b918fe72fa5fdd", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# Run this cell without changes\n", "import pandas as pd\n", "import itertools\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "import numpy as np\n", "from sklearn.linear_model import Lasso, Ridge\n", "from sklearn.metrics import mean_squared_error\n", "from sklearn.linear_model import LinearRegression\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import PolynomialFeatures"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "64344faaa2aff0fd709b6cb7b30ab89c", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# Run this cell without changes\n", "data = pd.read_csv('raw_data/advertising.csv').drop('Unnamed: 0',axis=1)\n", "data.describe()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "ff89f4de7bd81650243d398dabc6a494", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# Run this cell without changes\n", "X = data.drop('sales', axis=1)\n", "y = data['sales']"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "63f43bbf30615821bf67123b1e18b075", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# Run this cell without changes\n", "# splits the data into training and testing set. Do not change the random state please!\n", "X_train , X_test, y_train, y_test = train_test_split(X, y,random_state=2019)"]}, {"cell_type": "code", "execution_count": 4, "metadata": {"nbgrader": {"grade": false, "grade_id": "7cb012dccc8727ad61c33e1dd0e3e5ad", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [], "source": ["### BEGIN SOLUTION\n\n", "\nfrom test_scripts.test_class import Test\ntest = Test()\n\n", "# split the data into training and testing set. Do not change the random state please!\n", "X_train , X_test, y_train, y_test = train_test_split(X, y,random_state=2019)", "\n\ntest.save()\n\n", "\n\n### END SOLUTION"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": true, "grade_id": "fdc437f9a9b69f9a4bb1cdc5dc5a91d4", "locked": true, "points": 1, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL", "\n", "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS", "\n", "\n", "### BEGIN HIDDEN TESTS", "\n", "\nfrom test_scripts.test_class import Test\n", "test = Test()\n\n", "test.run_test()\n\n", "\n", "### END HIDDEN TESTS"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "1fb593eab3bc756b534afc39bcf3bcb0", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["### 1. We'd like to add a bit of complexity to the model created in the example above, and we will do it by adding some polynomial terms. Write a function to calculate train and test error for different polynomial degrees.\n", "\n", "This function should:\n", "* take `degree` as a parameter that will be used to create polynomial features to be used in a linear regression model\n", "* create a PolynomialFeatures object for each degree and fit a linear regression model using the transformed data\n", "* calculate the mean square error for each level of polynomial\n", "* return the `train_error` and `test_error` \n"]}, {"cell_type": "code", "execution_count": 5, "metadata": {"nbgrader": {"grade": false, "grade_id": "f35fcc3bbd26df30e0882818d7ace548", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [], "source": ["### BEGIN SOLUTION\n\n", "\nfrom test_scripts.test_class import Test\ntest = Test()\n\n", "\n", "# do a polynomial regression\n", "def polynomial_regression(degree):\n", "    \"\"\"\n", "    Calculate train and test error for a linear regression with polynomial features.\n", "    (Hint: use PolynomialFeatures)\n", "    \n", "    input: Polynomial degree\n", "    output: Mean squared error for train and test set\n", "    \"\"\"\n", "    poly = PolynomialFeatures(degree=degree,interaction_only=False)\n", "    X_poly_train = poly.fit_transform(X_train)\n", "    X_poly_test = poly.transform(X_test)\n", "    lr_poly = LinearRegression()\n", "    lr_poly.fit(X_poly_train,y_train)\n", "    train_error = mean_squared_error(y_train, lr_poly.predict(X_poly_train))\n", "    test_error = mean_squared_error(y_test, lr_poly.predict(X_poly_test))\n", "    return train_error, test_error", "\n\ntest.save()\n\n", "\n\n### END SOLUTION"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": true, "grade_id": "ba146facebf026d7c3a422923a689605", "locked": true, "points": 1, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL", "\n", "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS", "\n", "\n", "### BEGIN HIDDEN TESTS", "\n", "\nfrom test_scripts.test_class import Test\n", "test = Test()\n\n", "test.run_test()\n\n", "\n", "### END HIDDEN TESTS"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "01849367083d3c28ac6572e544e1ad9a", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["#### Try out your new function"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "74158120d9529c3f235b1045211372d6", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# Run this cell without changes\n", "polynomial_regression(3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "d39816bf4cb4be5f0310a57c638ea80b", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# Run this cell without changes\n", "polynomial_regression(4)"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "e4efd43773d07238229a7543003a23ee", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["#### Check your answers\n", "\n", "Approximate MSE for degree 3:\n", "- Train: 0.242\n", "- Test: 0.153\n", "\n", "Approximate MSE for degree 4:\n", "- Train: 0.182\n", "- Test: 1.95"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "327b1f4cd71d6a71b448ffcfa42c9a4d", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["### 2. What is the optimal number of degrees for our polynomial features in this model? In general, how does increasing the polynomial degree relate to the Bias/Variance tradeoff?  (Note that this graph shows RMSE and not MSE.)\n", "\n", "<img src =\"visuals/rsme_poly_2.png\" width = \"600\">\n", "\n", "<!---\n", "fig, ax = plt.subplots(figsize=(7, 7))\n", "degree = list(range(1, 10 + 1))\n", "ax.plot(degree, error_train[0:len(degree)], \"-\", label=\"Train Error\")\n", "ax.plot(degree, error_test[0:len(degree)], \"-\", label=\"Test Error\")\n", "ax.set_yscale(\"log\")\n", "ax.set_xlabel(\"Polynomial Feature Degree\")\n", "ax.set_ylabel(\"Root Mean Squared Error\")\n", "ax.legend()\n", "ax.set_title(\"Relationship Between Degree and Error\")\n", "fig.tight_layout()\n", "fig.savefig(\"visuals/rsme_poly.png\",\n", "            dpi=150,\n", "            bbox_inches=\"tight\")\n", "--->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "5d7316b28b2d55e0ce30467e199a15df", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [], "source": ["### BEGIN SOLUTION\n\n", "\nfrom test_scripts.test_class import Test\ntest = Test()\n\n", "# The optimal number of features in this example is 3 because the testing error \n", "# is minimized at this point, and it increases dramatically with a higher degree polynomial. \n", "# As we increase the polynomial features, it is going to cause our training error to decrease, \n", "# which decreases the bias but increases the variance (the testing error increases). \n", "# In other words, the more complex the model, the higher the chance of overfitting.", "\n\ntest.save()\n\n", "\n\n### END SOLUTION"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": true, "grade_id": "14dd87e14be6cc5a516cf2df4fc34465", "locked": true, "points": 1, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL", "\n", "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS", "\n", "\n", "### BEGIN HIDDEN TESTS", "\n", "\nfrom test_scripts.test_class import Test\n", "test = Test()\n\n", "test.run_test()\n\n", "\n", "### END HIDDEN TESTS"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "adda862983eb04242e2163980e970230", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["### 3. In general what methods would you can use to reduce overfitting and underfitting? Provide an example for both and explain how each technique works to reduce the problems of underfitting and overfitting."]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "e4ad4a8f65419763152b3263216cea4d", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [], "source": ["### BEGIN SOLUTION\n\n", "\nfrom test_scripts.test_class import Test\ntest = Test()\n\n", "# Overfitting: Regularization. With regularization, more complex models are penalized. \n", "# This ensures that the models are not trained to too much \"noise.\"\n", "\n", "# Underfitting: Feature engineering. By adding additional features, you enable your \n", "# machine learning models to gain insights about your data.", "\n\ntest.save()\n\n", "\n\n### END SOLUTION"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": true, "grade_id": "ca0b73ec25f49e41046c6fde8160bf5c", "locked": true, "points": 1, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL", "\n", "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS", "\n", "\n", "### BEGIN HIDDEN TESTS", "\n", "\nfrom test_scripts.test_class import Test\n", "test = Test()\n\n", "test.run_test()\n\n", "\n", "### END HIDDEN TESTS"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "d1fee8d42f64342aeb29b519d85a1bc0", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["### 4. What is the difference between the two types of regularization for linear regression?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "89f6de5e321584d60f71306179e0b234", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [], "source": ["### BEGIN SOLUTION\n\n", "\nfrom test_scripts.test_class import Test\ntest = Test()\n\n", "# L1 or Lasso Regression adds a term to the cost function which reduces some smaller weights down to zero.\n", "# L2 or Ridge Regression adds a term to the cost function which penalizes weights based on their size,\n", "# bringing all of them closer to zero.", "\n\ntest.save()\n\n", "\n\n### END SOLUTION"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": true, "grade_id": "55899fb72c6c2e6427455152501490cc", "locked": true, "points": 1, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL", "\n", "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS", "\n", "\n", "### BEGIN HIDDEN TESTS", "\n", "\nfrom test_scripts.test_class import Test\n", "test = Test()\n\n", "test.run_test()\n\n", "\n", "### END HIDDEN TESTS"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "1fc1e2260d2806a7d16c108f4f4d430a", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["### 5. Why is scaling input variables a necessary step before regularization?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "0d7c9ea9ff2880bd79ebdd7863d077c6", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [], "source": ["### BEGIN SOLUTION\n\n", "\nfrom test_scripts.test_class import Test\ntest = Test()\n\n", "# Regularization adjusts feature weights depending on their magnitude.\n", "# Feature weights themselves depend on both the feature importance and the magnitude of the input variable.\n", "# Therefore, it's important to control for the magnitude of the input variable by scaling all features the same.", "\n\ntest.save()\n\n", "\n\n### END SOLUTION"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": true, "grade_id": "d9d102531dac88892e2d490b05b6aa1b", "locked": true, "points": 1, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL", "\n", "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS", "\n", "\n", "### BEGIN HIDDEN TESTS", "\n", "\nfrom test_scripts.test_class import Test\n", "test = Test()\n\n", "test.run_test()\n\n", "\n", "### END HIDDEN TESTS"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.3"}}, "nbformat": 4, "nbformat_minor": 4}